{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff164306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c808d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Learning from compressed observations</td>\n",
       "      <td>The problem of statistical learning is to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sensor Networks with Random Links: Topology De...</td>\n",
       "      <td>In a sensor network, in practice, the commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The on-line shortest path problem under partia...</td>\n",
       "      <td>The on-line shortest path problem is conside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A neural network approach to ordinal regression</td>\n",
       "      <td>Ordinal regression is an important type of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Parametric Learning and Monte Carlo Optimization</td>\n",
       "      <td>This paper uncovers and explores the close r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117587</th>\n",
       "      <td>4995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Detecting COVID-19 Conspiracy Theories with Tr...</td>\n",
       "      <td>The sharing of fake news and conspiracy theori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117588</th>\n",
       "      <td>4996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair Feature Subset Selection using Multiobjec...</td>\n",
       "      <td>The feature subset selection problem aims at s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117589</th>\n",
       "      <td>4997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Simple Duality Proof for Wasserstein Distrib...</td>\n",
       "      <td>We present a short and elementary proof of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117590</th>\n",
       "      <td>4998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Combined Learning of Neural Network Weights fo...</td>\n",
       "      <td>We introduce CoLN, Combined Learning of Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117591</th>\n",
       "      <td>4999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adapting and Evaluating Influence-Estimation M...</td>\n",
       "      <td>Influence estimation analyzes how changes to t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117592 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0  \\\n",
       "0                  0         0.0   \n",
       "1                  1         1.0   \n",
       "2                  2         2.0   \n",
       "3                  3         3.0   \n",
       "4                  4         4.0   \n",
       "...              ...         ...   \n",
       "117587          4995         NaN   \n",
       "117588          4996         NaN   \n",
       "117589          4997         NaN   \n",
       "117590          4998         NaN   \n",
       "117591          4999         NaN   \n",
       "\n",
       "                                                    title  \\\n",
       "0                   Learning from compressed observations   \n",
       "1       Sensor Networks with Random Links: Topology De...   \n",
       "2       The on-line shortest path problem under partia...   \n",
       "3         A neural network approach to ordinal regression   \n",
       "4        Parametric Learning and Monte Carlo Optimization   \n",
       "...                                                   ...   \n",
       "117587  Detecting COVID-19 Conspiracy Theories with Tr...   \n",
       "117588  Fair Feature Subset Selection using Multiobjec...   \n",
       "117589  A Simple Duality Proof for Wasserstein Distrib...   \n",
       "117590  Combined Learning of Neural Network Weights fo...   \n",
       "117591  Adapting and Evaluating Influence-Estimation M...   \n",
       "\n",
       "                                                 abstract  \n",
       "0         The problem of statistical learning is to co...  \n",
       "1         In a sensor network, in practice, the commun...  \n",
       "2         The on-line shortest path problem is conside...  \n",
       "3         Ordinal regression is an important type of l...  \n",
       "4         This paper uncovers and explores the close r...  \n",
       "...                                                   ...  \n",
       "117587  The sharing of fake news and conspiracy theori...  \n",
       "117588  The feature subset selection problem aims at s...  \n",
       "117589  We present a short and elementary proof of the...  \n",
       "117590  We introduce CoLN, Combined Learning of Neural...  \n",
       "117591  Influence estimation analyzes how changes to t...  \n",
       "\n",
       "[117592 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"ML-Arxiv-Papers.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = (df[\"title\"].fillna('') + \" \" + df[\"abstract\"].fillna('')).str.strip()\n",
    "\n",
    "\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "def preprocess_parquet(texts, tokens_only=False):\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "\n",
    "train_corpus = list(preprocess_parquet(texts))\n",
    "test_corpus = list(preprocess_parquet(texts, tokens_only=True))  \n",
    "\n",
    "print(train_corpus[2])\n",
    "print(test_corpus[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f869c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train doc: TaggedDocument(['guided', 'random', 'forest', 'in', 'the', 'rrf', 'package', 'random', 'forest', 'rf', 'is', 'powerful', 'supervised', 'learner', 'and', 'has', 'been', 'popularly', 'used', 'in', 'many', 'applications', 'such', 'as', 'bioinformatics', 'in', 'this', 'work', 'we', 'propose', 'the', 'guided', 'random', 'forest', 'grf', 'for', 'feature', 'selection', 'similar', 'to', 'feature', 'selection', 'method', 'called', 'guided', 'regularized', 'random', 'forest', 'grrf', 'grf', 'is', 'built', 'using', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'rf', 'however', 'the', 'trees', 'in', 'grrf', 'are', 'built', 'sequentially', 'are', 'highly', 'correlated', 'and', 'do', 'not', 'allow', 'for', 'parallel', 'computing', 'while', 'the', 'trees', 'in', 'grf', 'are', 'built', 'independently', 'and', 'can', 'be', 'implemented', 'in', 'parallel', 'experiments', 'on', 'high', 'dimensional', 'gene', 'data', 'sets', 'show', 'that', 'with', 'fixed', 'parameter', 'value', 'without', 'tuning', 'the', 'parameter', 'rf', 'applied', 'to', 'features', 'selected', 'by', 'grf', 'outperforms', 'rf', 'applied', 'to', 'all', 'features', 'on', 'data', 'sets', 'and', 'of', 'them', 'have', 'significant', 'differences', 'at', 'the', 'level', 'therefore', 'both', 'accuracy', 'and', 'are', 'significantly', 'improved', 'grf', 'selects', 'more', 'features', 'than', 'grrf', 'however', 'leads', 'to', 'better', 'classification', 'accuracy', 'note', 'in', 'this', 'work', 'the', 'guided', 'random', 'forest', 'is', 'guided', 'by', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'random', 'forest', 'however', 'it', 'can', 'also', 'be', 'guided', 'by', 'other', 'methods', 'such', 'as', 'human', 'insights', 'by', 'specifying', 'lambda_i', 'grf', 'can', 'be', 'used', 'in', 'rrf', 'and', 'later', 'versions', 'package', 'that', 'also', 'includes', 'the', 'regularized', 'random', 'forest', 'methods'], [2])\n",
      "Sample test doc: ['guided', 'random', 'forest', 'in', 'the', 'rrf', 'package', 'random', 'forest', 'rf', 'is', 'powerful', 'supervised', 'learner', 'and', 'has', 'been', 'popularly', 'used', 'in', 'many', 'applications', 'such', 'as', 'bioinformatics', 'in', 'this', 'work', 'we', 'propose', 'the', 'guided', 'random', 'forest', 'grf', 'for', 'feature', 'selection', 'similar', 'to', 'feature', 'selection', 'method', 'called', 'guided', 'regularized', 'random', 'forest', 'grrf', 'grf', 'is', 'built', 'using', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'rf', 'however', 'the', 'trees', 'in', 'grrf', 'are', 'built', 'sequentially', 'are', 'highly', 'correlated', 'and', 'do', 'not', 'allow', 'for', 'parallel', 'computing', 'while', 'the', 'trees', 'in', 'grf', 'are', 'built', 'independently', 'and', 'can', 'be', 'implemented', 'in', 'parallel', 'experiments', 'on', 'high', 'dimensional', 'gene', 'data', 'sets', 'show', 'that', 'with', 'fixed', 'parameter', 'value', 'without', 'tuning', 'the', 'parameter', 'rf', 'applied', 'to', 'features', 'selected', 'by', 'grf', 'outperforms', 'rf', 'applied', 'to', 'all', 'features', 'on', 'data', 'sets', 'and', 'of', 'them', 'have', 'significant', 'differences', 'at', 'the', 'level', 'therefore', 'both', 'accuracy', 'and', 'are', 'significantly', 'improved', 'grf', 'selects', 'more', 'features', 'than', 'grrf', 'however', 'leads', 'to', 'better', 'classification', 'accuracy', 'note', 'in', 'this', 'work', 'the', 'guided', 'random', 'forest', 'is', 'guided', 'by', 'the', 'importance', 'scores', 'from', 'an', 'ordinary', 'random', 'forest', 'however', 'it', 'can', 'also', 'be', 'guided', 'by', 'other', 'methods', 'such', 'as', 'human', 'insights', 'by', 'specifying', 'lambda_i', 'grf', 'can', 'be', 'used', 'in', 'rrf', 'and', 'later', 'versions', 'package', 'that', 'also', 'includes', 'the', 'regularized', 'random', 'forest', 'methods']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_parquet(\"ML-Arxiv-Papers.parquet\").sample(n=1000, random_state=42)\n",
    "\n",
    "\n",
    "df[\"text\"] = (df[\"title\"].fillna('') + \" \" + df[\"abstract\"].fillna('')).str.strip()\n",
    "\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "\n",
    "\n",
    "def preprocess_parquet(texts, tokens_only=False):\n",
    "    for i, text in enumerate(texts):\n",
    "        tokens = gensim.utils.simple_preprocess(text)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(preprocess_parquet(texts))\n",
    "test_corpus = list(preprocess_parquet(texts, tokens_only=True))\n",
    "\n",
    "print(\"Sample train doc:\", train_corpus[2])\n",
    "print(\"Sample test doc:\", test_corpus[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227b6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8057b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21054923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cac0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce2a815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1372fdb3d90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1585c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08790659 -0.15608478  0.04763642 -0.02384534  0.44756308 -0.15677297\n",
      "  0.18224443  0.38171116 -0.11254364  0.20638946  0.00474802 -0.35088018\n",
      "  0.08199678 -0.12789318 -0.36796916 -0.14833704  0.5732824   0.12079011\n",
      "  0.4978068  -0.05393522 -0.16476229 -0.05717217 -0.08952983  0.03479337\n",
      " -0.12052672 -0.51582813 -0.03802516  0.24639948 -0.17839184 -0.189645\n",
      "  0.07991289 -0.05492688  0.30556113 -0.1889699   0.17209831 -0.51748013\n",
      "  0.3253089   0.06524195 -0.04967424  0.28368092  0.47358108  0.13111\n",
      " -0.37023544 -0.52133363  0.5354818  -0.20109093  0.36223802  0.24787362\n",
      "  0.02772081  0.22813538]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a662eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1000})\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])\n",
    "\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb57172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (927): Â«zero shot learning and knowledge transfer in music classification and tagging music classification and tagging is conducted through categorical supervised learning with fixed set of labels in principle this cannot make predictions on unseen labels zero shot learning is an approach to solve the problem by using side information about the semantic labels we recently investigated this concept of zero shot learning in music classification and tagging task by projecting both audio and label space on single semantic space in this work we extend the work to verify the generalization ability of zero shot learning model by conducting knowledge transfer to different music corporaÂ»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (927, 0.9441136717796326): Â«zero shot learning and knowledge transfer in music classification and tagging music classification and tagging is conducted through categorical supervised learning with fixed set of labels in principle this cannot make predictions on unseen labels zero shot learning is an approach to solve the problem by using side information about the semantic labels we recently investigated this concept of zero shot learning in music classification and tagging task by projecting both audio and label space on single semantic space in this work we extend the work to verify the generalization ability of zero shot learning model by conducting knowledge transfer to different music corporaÂ»\n",
      "\n",
      "MEDIAN (463, 0.2693268060684204): Â«agnostic physics driven deep learning this work establishes that physical system can perform statistical learning without gradient computations via an agnostic equilibrium propagation aeqprop procedure that combines energy minimization homeostatic control and nudging towards the correct response in aeqprop the specifics of the system do not have to be known the procedure is based only on external manipulations and produces stochastic gradient descent without explicit gradient computations thanks to nudging the system performs true order one gradient step for each training sample in contrast with order zero methods like reinforcement or evolutionary strategies which rely on trial and error this procedure considerably widens the range of potential hardware for statistical learning to any system with enough controllable parameters even if the details of the system are poorly known aeqprop also establishes that in natural bio physical systems genuine gradient based statistical learning may result from generic relatively simple mechanisms without backpropagation and its requirement for analytic knowledge of partial derivativesÂ»\n",
      "\n",
      "LEAST (865, -0.15511882305145264): Â«quantum deep learning for mutant covid strain prediction new covid epidemic strains like delta and omicron with increased and pathogenicity emerge and spread across the whole world rapidly while causing high mortality during the pandemic period early prediction of possible variants especially spike protein of covid epidemic strains based on available mutated sars cov rna sequences may lead to early prevention and treatment here combining the advantage of quantum and quantum inspired algorithms with the wide application of deep learning we propose development tool named deepquantum and use this software to realize the goal of predicting spike protein variation structure of covid epidemic strains in addition this hybrid quantum classical model for the first time achieves quantum inspired blur convolution similar to classical depthwise convolution and also successfully applies quantum progressive training with quantum circuits both of which guarantee that our model is the quantum counterpart of the famous style based gan the results state that the fidelities of random generating spike protein variation structure are always beyond for delta for omicron the training loss curve is more stable and converges better with multiple loss functions compared with the corresponding classical algorithm at last evidences that quantum inspired algorithms promote the classical deep learning and hybrid models effectively predict the mutant strains are strongÂ»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): Â«{}Â»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: Â«%sÂ»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23cbffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp39-cp39-win_amd64.whl (671 kB)\n",
      "     -------------------------------------- 671.2/671.2 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (1.24.3)\n",
      "Collecting cramjam>=2.3\n",
      "  Downloading cramjam-2.9.1-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (21.3)\n",
      "Collecting pandas>=1.5.0\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from fastparquet) (2024.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2022.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     -------------------------------------- 347.8/347.8 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->fastparquet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: tzdata, cramjam, pandas, fastparquet\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.4\n",
      "    Uninstalling pandas-1.4.4:\n",
      "      Successfully uninstalled pandas-1.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\user\\\\anaconda3\\\\Lib\\\\site-packages\\\\~andas\\\\_libs\\\\algos.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b6a7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = pd.read_csv(\"hf://datasets/CShorten/ML-ArXiv-Papers/ML-Arxiv-Papers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d5b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_parquet(\"ML-Arxiv-Papers.parquet\", engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d8947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92703d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
